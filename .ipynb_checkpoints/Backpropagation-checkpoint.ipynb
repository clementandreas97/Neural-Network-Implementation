{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Data\\App\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import done.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "from numpy.random import seed\n",
    "from random import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import arff\n",
    "\n",
    "print('Import done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2    3\n",
      "0   0.0  85.0  85.0  0.0\n",
      "1   0.0  80.0  90.0  1.0\n",
      "2   1.0  83.0  86.0  0.0\n",
      "3   2.0  70.0  96.0  0.0\n",
      "4   2.0  68.0  80.0  0.0\n",
      "5   2.0  65.0  70.0  1.0\n",
      "6   1.0  64.0  65.0  1.0\n",
      "7   0.0  72.0  95.0  0.0\n",
      "8   0.0  69.0  70.0  0.0\n",
      "9   2.0  75.0  80.0  0.0\n",
      "10  0.0  75.0  70.0  1.0\n",
      "11  1.0  72.0  90.0  1.0\n",
      "12  1.0  81.0  75.0  0.0\n",
      "13  2.0  71.0  91.0  1.0\n",
      "\n",
      "[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Data (weather)\n",
    "\n",
    "datafile = arff.load(open('weather.arff'))\n",
    "weather = pd.DataFrame(datafile['data'])\n",
    "# weather = weather.drop(columns=[1,2])\n",
    "\n",
    "weather[0] = weather[0].map(dict(sunny=0, overcast=1, rainy=2)).astype(float)\n",
    "weather[3] = weather[3].map(dict(TRUE=1, FALSE=0)).astype(float)\n",
    "weather[4] = weather[4].map(dict(yes=1, no=0)).astype(float)\n",
    "\n",
    "x = weather.drop(columns=[4])\n",
    "y = weather[4]\n",
    "\n",
    "print(x)\n",
    "print()\n",
    "print(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    outlook  temp  humidity  windy\n",
      "0       0.0   0.0       1.0    0.0\n",
      "1       0.0   0.0       1.0    1.0\n",
      "2       1.0   0.0       1.0    0.0\n",
      "3       2.0   1.0       1.0    0.0\n",
      "4       2.0   2.0       0.0    0.0\n",
      "5       2.0   2.0       0.0    1.0\n",
      "6       1.0   2.0       0.0    1.0\n",
      "7       0.0   1.0       1.0    0.0\n",
      "8       0.0   2.0       0.0    0.0\n",
      "9       2.0   1.0       0.0    0.0\n",
      "10      0.0   1.0       0.0    1.0\n",
      "11      1.0   1.0       1.0    1.0\n",
      "12      1.0   0.0       0.0    0.0\n",
      "13      2.0   1.0       1.0    1.0\n",
      "\n",
      "[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Data (tennis)\n",
    "\n",
    "weather = pd.read_csv('tennis.csv')\n",
    "\n",
    "weather.outlook = weather.outlook.map(dict(sunny=0, overcast=1, rainy=2)).astype(float)\n",
    "weather.temp = weather.temp.map(dict(hot=0, mild=1, cool=2)).astype(float)\n",
    "weather.humidity = weather.humidity.map(dict(normal=0, high=1)).astype(float)\n",
    "weather.windy = weather.windy.astype(float)\n",
    "weather.play = weather.play.map(dict(yes=1, no=0)).astype(float)\n",
    "\n",
    "x = weather.drop(columns=['play'])\n",
    "y = weather.play\n",
    "\n",
    "print(x)\n",
    "print()\n",
    "print(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train\n",
      "[[0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [2. 2. 0. 1.]\n",
      " [0. 2. 0. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [2. 1. 1. 1.]\n",
      " [2. 2. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [2. 1. 1. 0.]\n",
      " [1. 2. 0. 1.]]\n",
      "\n",
      "y_train\n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1.]\n",
      "\n",
      "x_test\n",
      "[[2. 1. 0. 0.]\n",
      " [1. 1. 1. 1.]]\n",
      "\n",
      "y_test\n",
      "[1. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "print('x_train')\n",
    "print(x_train)\n",
    "print()\n",
    "\n",
    "print('y_train')\n",
    "print(y_train)\n",
    "print()\n",
    "\n",
    "print('x_test')\n",
    "print(x_test)\n",
    "print()\n",
    "\n",
    "print('y_test')\n",
    "print(y_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backpropagation class\n",
    "\n",
    "class BackPropagation:\n",
    "    n_inputs = 1\n",
    "    n_hiddens = [1]\n",
    "    n_outputs = 1\n",
    "    l_rate = 0.5\n",
    "    n_epoch = 20\n",
    "    batch_size = 1\n",
    "    momentum = 1\n",
    "    network = list()\n",
    "    \n",
    "    def __init__(self, n_inputs, n_hiddens, l_rate, n_epoch, batch_size, momentum):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hiddens = n_hiddens\n",
    "        self.l_rate = l_rate\n",
    "        self.n_epoch = n_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.momentum = momentum\n",
    "        self.network = list()\n",
    "\n",
    "        hidden_layer = [{'weights':[random() for i in range(self.n_inputs + 1)]} for i in range(self.n_hiddens[0])]\n",
    "        self.network.append(hidden_layer)\n",
    "\n",
    "        for i in range(1, min(len(n_hiddens), 10)):\n",
    "            hidden_layer = [{'weights':[random() for j in range(self.n_hiddens[i-1] + 1)]} for i in range(self.n_hiddens[i])]\n",
    "            self.network.append(hidden_layer)\n",
    "\n",
    "        output_layer = [{'weights':[random() for i in range(self.n_hiddens[-1] + 1)]} for i in range(self.n_outputs)]\n",
    "        self.network.append(output_layer)\n",
    "        \n",
    "    def activate(self, weights, inputs):\n",
    "        activation = weights[-1]\n",
    "        for i in range(len(weights)-1):\n",
    "            activation += weights[i] * inputs[i]\n",
    "        return activation\n",
    "\n",
    "    def transfer(self, activation):\n",
    "        return 1.0 / (1.0 + np.exp(-activation))\n",
    "\n",
    "    def forward_propagate(self, network, init_input):\n",
    "        inputs = init_input\n",
    "        for layer in network:\n",
    "            new_inputs = []\n",
    "            for neuron in layer:\n",
    "                activation = self.activate(neuron['weights'], inputs)\n",
    "                neuron['output'] = self.transfer(activation)\n",
    "                new_inputs.append(neuron['output'])\n",
    "            inputs = new_inputs\n",
    "        return inputs\n",
    "    \n",
    "    def transfer_derivative(self, output):\n",
    "        return output * (1.0 - output)\n",
    "\n",
    "    def backward_propagate_error(self, network, expected):\n",
    "        for i in reversed(range(len(network))):\n",
    "            layer = network[i]\n",
    "            errors = list()\n",
    "            if i != len(network)-1:\n",
    "                for j in range(len(layer)):\n",
    "                    error = 0.0\n",
    "                    for neuron in network[i + 1]:\n",
    "                        error += (neuron['weights'][j] * neuron['delta'])\n",
    "                    errors.append(error)\n",
    "            else:\n",
    "                for j in range(len(layer)):\n",
    "                    neuron = layer[j]\n",
    "                    a = 1\n",
    "                    errors.append(expected[j] - neuron['output'])\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                neuron['delta'] = errors[j] * self.transfer_derivative(neuron['output'])\n",
    "    \n",
    "    def initialize_delta_weight(self, network):\n",
    "        delta_weight = []\n",
    "        for layer in network:\n",
    "            delta_weight.append([])\n",
    "            for neuron in layer:\n",
    "                delta_weight[-1].append(np.zeros(len(neuron['weights'])))\n",
    "        return delta_weight\n",
    "\n",
    "    def accumulate_delta_weight(self, network, init_input, l_rate, momentum, delta_weight):\n",
    "        for i in range(len(network)):\n",
    "            inputs = init_input[:-1]\n",
    "            if i != 0:\n",
    "                inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "            for j in range(len(network[i])):\n",
    "                for k in range(len(inputs)):\n",
    "                    delta_weight[i][j][k] += (l_rate * network[i][j]['delta'] * inputs[k] + momentum * network[i][j]['weights'][k]) \n",
    "                delta_weight[i][j][-1] += (l_rate * network[i][j]['delta'] + momentum * network[i][j]['weights'][-1]) \n",
    "\n",
    "    def update_weight(self, network, delta_weight):\n",
    "        for i in range(len(network)):\n",
    "            for j in range(len(network[i])):\n",
    "                for k in range(len(network[i][j]['weights'])):\n",
    "                    network[i][j]['weights'][k] += delta_weight[i][j][k]\n",
    "\n",
    "    def fit(self, init_inputs_x, init_inputs_y, validation_data = None):\n",
    "        init_inputs = list()\n",
    "        for i in range(0,len(init_inputs_x)):\n",
    "            init_inputs.append(np.append(init_inputs_x[i],init_inputs_y[i]))\n",
    "        for epoch in range(self.n_epoch):\n",
    "            sum_error = 0\n",
    "            batch_member_calculated = 0\n",
    "            delta_weight = self.initialize_delta_weight(self.network)\n",
    "            for init_data in init_inputs:\n",
    "                outputs = self.forward_propagate(self.network, init_data)\n",
    "                expected = [0 for i in range(self.n_outputs)]\n",
    "                expected[0] = init_data[-1]\n",
    "                sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "                self.backward_propagate_error(self.network, expected)\n",
    "\n",
    "                self.accumulate_delta_weight(self.network, init_data, self.l_rate, self.momentum, delta_weight)\n",
    "                batch_member_calculated += 1\n",
    "\n",
    "                if batch_member_calculated == self.batch_size:\n",
    "                    self.update_weight(self.network, delta_weight)\n",
    "                    batch_member_calculated = 0\n",
    "                    delta_weight = self.initialize_delta_weight(self.network)\n",
    "            if validation_data != None:\n",
    "                pred = self.predict(validation_data[0])\n",
    "                val_score = accuracy_score(pred, validation_data[1])\n",
    "                print('>epoch=%d, lrate=%.3f, error=%.3f, val_score=%.2f, outputs=%.2f' % (epoch, self.l_rate, sum_error, val_score, outputs[0]))\n",
    "            else:\n",
    "                print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, self.l_rate, sum_error))\n",
    "        tempnetwork = list()\n",
    "        for layer in self.network:\n",
    "            templayer = list()\n",
    "            for neuron in layer:\n",
    "                templayer.append({'weights' : neuron['weights']})\n",
    "            tempnetwork.append(templayer)\n",
    "        self.network = tempnetwork\n",
    "            \n",
    "    def predict(self, init_inputs):\n",
    "        labels = np.zeros(len(init_inputs))\n",
    "        for i in range(0,len(init_inputs)):\n",
    "            labels[i] = self.forward_propagate(self.network, init_inputs[i])[0].round()\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.500, error=4.090, val_score=1.00, outputs=0.88\n",
      ">epoch=1, lrate=0.500, error=3.791, val_score=1.00, outputs=0.82\n",
      ">epoch=2, lrate=0.500, error=3.476, val_score=1.00, outputs=0.75\n",
      ">epoch=3, lrate=0.500, error=3.261, val_score=1.00, outputs=0.68\n",
      ">epoch=4, lrate=0.500, error=3.163, val_score=1.00, outputs=0.65\n",
      ">epoch=5, lrate=0.500, error=3.125, val_score=1.00, outputs=0.63\n",
      ">epoch=6, lrate=0.500, error=3.109, val_score=1.00, outputs=0.62\n",
      ">epoch=7, lrate=0.500, error=3.101, val_score=1.00, outputs=0.62\n",
      ">epoch=8, lrate=0.500, error=3.094, val_score=1.00, outputs=0.62\n",
      ">epoch=9, lrate=0.500, error=3.088, val_score=1.00, outputs=0.62\n",
      ">epoch=10, lrate=0.500, error=3.083, val_score=1.00, outputs=0.62\n",
      ">epoch=11, lrate=0.500, error=3.077, val_score=1.00, outputs=0.62\n",
      ">epoch=12, lrate=0.500, error=3.071, val_score=1.00, outputs=0.62\n",
      ">epoch=13, lrate=0.500, error=3.064, val_score=1.00, outputs=0.62\n",
      ">epoch=14, lrate=0.500, error=3.056, val_score=1.00, outputs=0.62\n",
      ">epoch=15, lrate=0.500, error=3.048, val_score=1.00, outputs=0.62\n",
      ">epoch=16, lrate=0.500, error=3.039, val_score=1.00, outputs=0.62\n",
      ">epoch=17, lrate=0.500, error=3.030, val_score=1.00, outputs=0.62\n",
      ">epoch=18, lrate=0.500, error=3.019, val_score=1.00, outputs=0.62\n",
      ">epoch=19, lrate=0.500, error=3.007, val_score=1.00, outputs=0.62\n",
      "{'weights': [1.3150156556885604, 1.0540207136311532, -0.26604212647840253, 0.7412398382460647, 0.7315506535522804]}\n",
      "{'weights': [0.03529806283851505, 0.6838066345946466, 0.8480785621655791, 0.9135809915751002, 0.34720111389928554]}\n",
      "{'weights': [0.8002090282398613, -0.2762521164685624, 0.06759461894638963]}\n",
      "\n",
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Backpropagation training\n",
    "\n",
    "seed(1)\n",
    "tp = (x_test, y_test)\n",
    "bp = BackPropagation(n_inputs=4, n_hiddens=[2], l_rate=0.5, n_epoch=20, batch_size=1, momentum=0.001)\n",
    "bp.fit(x_train, y_train,tp)\n",
    "for layer in bp.network:\n",
    "    for neuron in layer:\n",
    "        print(neuron)\n",
    "print()\n",
    "print(bp.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.8305 - acc: 0.4167\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.7510 - acc: 0.5833\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 0s 995us/step - loss: 0.8385 - acc: 0.5000\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.8126 - acc: 0.3333\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 0s 997us/step - loss: 0.7385 - acc: 0.5833\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.7601 - acc: 0.4167\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.7534 - acc: 0.5000\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6964 - acc: 0.6667\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6500 - acc: 0.5833\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 0s 914us/step - loss: 0.6595 - acc: 0.4167\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 0s 997us/step - loss: 0.6548 - acc: 0.4167\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 0s 995us/step - loss: 0.7231 - acc: 0.6667\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6480 - acc: 0.7500\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 0s 995us/step - loss: 0.6838 - acc: 0.5833\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 0s 914us/step - loss: 0.6091 - acc: 0.6667\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 0s 997us/step - loss: 0.6261 - acc: 0.5833\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6350 - acc: 0.6667\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 0s 997us/step - loss: 0.6227 - acc: 0.5833\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5847 - acc: 0.7500\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 0s 914us/step - loss: 0.6346 - acc: 0.6667\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 0s 997us/step - loss: 0.6222 - acc: 0.6667\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5762 - acc: 0.7500\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 0s 914us/step - loss: 0.6511 - acc: 0.6667\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5760 - acc: 0.8333\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5171 - acc: 0.7500\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6383 - acc: 0.6667\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 0s 914us/step - loss: 0.5906 - acc: 0.6667\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 0s 914us/step - loss: 0.5498 - acc: 0.9167\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 0s 997us/step - loss: 0.5792 - acc: 0.7500\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 0s 997us/step - loss: 0.5660 - acc: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9170299 ],\n",
       "       [0.19932196]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keras training\n",
    "\n",
    "seed(1)\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=4, activation=\"sigmoid\", kernel_initializer=\"zeros\", bias_initializer=\"ones\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.7, momentum=0)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=30)\n",
    "model.predict(x_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
